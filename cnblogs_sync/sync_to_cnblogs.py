# cnblogs_sync/sync_to_cnblogs.py
#
# åšå®¢å›­æ–‡ç« å‘å¸ƒè„šæœ¬
#
# ã€åŠŸèƒ½è¯´æ˜ã€‘
# å°†æœ¬åœ° Markdown æ–‡ä»¶å‘å¸ƒåˆ°åšå®¢å›­ï¼ˆå•å‘ï¼šæœ¬åœ° â†’ åšå®¢å›­ï¼‰ï¼Œæ”¯æŒåŸºäºæœ¬åœ° JSON è®°å½•çš„å»é‡åˆ¤æ–­ã€‚
#
# ã€ç¯å¢ƒå˜é‡é…ç½®ã€‘
# ä½¿ç”¨å‰éœ€è¦è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼ˆé€šè¿‡ .env æ–‡ä»¶æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡ï¼‰ï¼š
#   - CNBLOGS_RPC_URL: åšå®¢å›­ RPC åœ°å€ï¼ˆå¿…éœ€ï¼‰
#   - CNBLOGS_BLOG_ID: åšå®¢ IDï¼ˆå¯é€‰ï¼Œæœªè®¾ç½®æ—¶ä¼šè‡ªåŠ¨è·å–ï¼‰
#   - CNBLOGS_USERNAME: ç”¨æˆ·åï¼ˆå¿…éœ€ï¼‰
#   - CNBLOGS_TOKEN: Tokenï¼ˆå¿…éœ€ï¼›å…¼å®¹ CNBLOGS_PASSWORDï¼‰
#   - CNBLOGS_PASSWORD: å¯†ç ï¼ˆå¯é€‰ï¼›ä½œä¸º CNBLOGS_TOKEN çš„åˆ«åï¼‰
#   - KNOWLEDGE_BASE_URL: çŸ¥è¯†åº“åŸºç¡€ URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šhttps://assemble.gitbook.io/assembleï¼‰
#   - CNBLOGS_SEARCH_URL: åšå®¢å›­ç«™å†…æœç´¢ URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šhttps://zzk.cnblogs.com/my/s/blogpost-pï¼‰
#   - INCREMENTAL_SYNC: æ˜¯å¦å¯ç”¨å¢é‡åŒæ­¥ï¼ˆé»˜è®¤ Trueï¼‰
#   - SYNC_STATE_GIT: æ˜¯å¦å°†çŠ¶æ€å†™å› Git åˆ†æ”¯ï¼ˆé»˜è®¤ Trueï¼‰
#   - SYNC_STATE_BRANCH: çŠ¶æ€åˆ†æ”¯åï¼ˆé»˜è®¤ sync-stateï¼‰
#   - SYNC_STATE_REMOTE: è¿œç«¯åï¼ˆé»˜è®¤ originï¼‰
#   - SYNC_STATE_REMOTE_URL: è¿œç«¯åœ°å€ï¼ˆå¯é€‰ï¼Œç”¨äºå†™å› PAT URLï¼‰
#   - SYNC_REPO_ROOT: ç›®æ ‡ä»“åº“æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼‰
#   - SYNC_RECORD_PATH: è®°å½•æ–‡ä»¶ç›¸å¯¹ä»“åº“è·¯å¾„ï¼ˆå¯é€‰ï¼‰
#   - SYNC_STATE_PATH: çŠ¶æ€æ–‡ä»¶ç›¸å¯¹ä»“åº“è·¯å¾„ï¼ˆå¯é€‰ï¼‰
#   - SYNC_RUN_LOG_PATH: è¿è¡Œè®°å½•æ–‡ä»¶ç›¸å¯¹ä»“åº“è·¯å¾„ï¼ˆå¯é€‰ï¼‰
#
# ã€ä½¿ç”¨æ–¹æ³•ã€‘
#
# 1. å‘å¸ƒæ–‡ç« åˆ°åšå®¢å›­ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨åˆå§‹åŒ–å‘å¸ƒè®°å½•ï¼‰ï¼š
#    a) è‡ªåŠ¨æ¨¡å¼ï¼ˆæ¨èï¼‰ï¼šä¸æŒ‡å®šæ–‡ä»¶ï¼Œè‡ªåŠ¨æ‰«æä»“åº“ä¸­æ‰€æœ‰ .md æ–‡ä»¶
#       python cnblogs_sync/sync_to_cnblogs.py
#    b) æ‰‹åŠ¨æ¨¡å¼ï¼šæŒ‡å®šè¦å‘å¸ƒçš„æ–‡ä»¶
#       python cnblogs_sync/sync_to_cnblogs.py <file1.md> [file2.md] ...
#    è¯´æ˜ï¼šå°† Markdown æ–‡ä»¶å‘å¸ƒåˆ°åšå®¢å›­
#          - è‹¥å‘å¸ƒè®°å½•ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨ä» API è·å–æœ€è¿‘ 300 ç¯‡æ–‡ç« ç”Ÿæˆè®°å½•
#          - å¦‚æœæ–‡ç« å·²åœ¨æœ¬åœ°è®°å½•ä¸­ï¼ˆå·²å‘å¸ƒè¿‡ï¼‰ï¼Œæ ¹æ® FORCE_OVERWRITE_EXISTING å¼€å…³å†³å®šæ˜¯å¦æ›´æ–°
#          - å¦‚æœæ˜¯æ–°æ–‡ç« ï¼Œç›´æ¥å‘å¸ƒå¹¶è‡ªåŠ¨æ›´æ–°æœ¬åœ°è®°å½•
#          - è‡ªåŠ¨æ¨¡å¼ä¼šæ’é™¤ .gitã€.githubã€node_modulesã€cnblogs_sync ç­‰ç›®å½•
#
# ã€é…ç½®é€‰é¡¹ã€‘
# - FORCE_OVERWRITE_EXISTING: æ˜¯å¦æ›´æ–°å·²å­˜åœ¨çš„æ–‡ç« ï¼ˆé»˜è®¤ Trueï¼‰
#   è®¾ç½®ä¸º True æ—¶ï¼Œå·²å­˜åœ¨çš„æ–‡ç« ä¼šè¢«æ›´æ–°ï¼›False æ—¶è·³è¿‡å·²å­˜åœ¨çš„æ–‡ç« 
#
# ã€æœ¬åœ°è®°å½•æ–‡ä»¶ã€‘
# - ä½ç½®ï¼šé»˜è®¤åœ¨ä»“åº“å†…çš„ `.cnblogs_sync/.cnblogs_sync_record.json`
# - æ ¼å¼ï¼š{ "æ–‡ç« æ ‡é¢˜": "post_id", ... }
# - ä½œç”¨ï¼šè®°å½•å·²å‘å¸ƒåˆ°åšå®¢å›­çš„æ–‡ç« ï¼Œé¿å…é‡å¤å‘å¸ƒ

import os
import sys
import re
import json
import time
import subprocess
import tempfile
import shutil
import xmlrpc.client
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
# from urllib.parse import quote # ä¸å†éœ€è¦è¿™ä¸ªæ¨¡å—ï¼Œå¯ä»¥ç§»é™¤

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# --- é…ç½®ä¿¡æ¯ ---
RPC_URL = os.getenv("CNBLOGS_RPC_URL")
BLOG_ID = os.getenv("CNBLOGS_BLOG_ID")
USERNAME = os.getenv("CNBLOGS_USERNAME")
PASSWORD = os.getenv("CNBLOGS_TOKEN") or os.getenv("CNBLOGS_PASSWORD")
# çŸ¥è¯†åº“å’Œåšå®¢å›­æœç´¢ URL é…ç½®
KNOWLEDGE_BASE_URL = os.getenv("KNOWLEDGE_BASE_URL", "https://assemble.gitbook.io/assemble")
CNBLOGS_SEARCH_URL = os.getenv("CNBLOGS_SEARCH_URL", "https://zzk.cnblogs.com/my/s/blogpost-p")

# --- Git / è¿è¡Œç¯å¢ƒå°ä¼˜åŒ– ---
# é¿å…åœ¨æ— äº¤äº’ç¯å¢ƒï¼ˆZeabur/Cronï¼‰é‡Œ git push è§¦å‘å‡­æ®äº¤äº’å¡æ­»
os.environ.setdefault("GIT_TERMINAL_PROMPT", "0")

# --- è¡Œä¸ºå¼€å…³ ---
FORCE_OVERWRITE_EXISTING = os.getenv("FORCE_OVERWRITE_EXISTING", "true").lower() in {"1", "true", "yes", "y", "on"}

# --- ä»“åº“æ ¹ç›®å½•ï¼ˆæ”¯æŒå¤–éƒ¨ä¼ å…¥ï¼‰ ---
REPO_ROOT = Path(os.getenv("SYNC_REPO_ROOT", Path(__file__).parent.parent)).resolve()

# --- è®°å½•/çŠ¶æ€æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ç›¸å¯¹ä»“åº“æ ¹ç›®å½•ï¼‰ ---
SYNC_RECORD_PATH = os.getenv(
    "SYNC_RECORD_PATH",
    ".cnblogs_sync/.cnblogs_sync_record.json"
)
SYNC_STATE_PATH = os.getenv(
    "SYNC_STATE_PATH",
    ".cnblogs_sync/state.json"
)
SYNC_RUN_LOG_PATH = os.getenv(
    "SYNC_RUN_LOG_PATH",
    ".cnblogs_sync/run_history.jsonl"
)

def resolve_repo_path(path_str):
    """å°†è·¯å¾„è§£æä¸ºä»“åº“å†…ç»å¯¹è·¯å¾„ï¼ˆæ”¯æŒç»å¯¹è·¯å¾„ï¼‰"""
    p = Path(path_str)
    return p if p.is_absolute() else (REPO_ROOT / p)

# --- æœ¬åœ°å‘å¸ƒè®°å½•æ–‡ä»¶è·¯å¾„ ---
SYNC_RECORD_FILE = resolve_repo_path(SYNC_RECORD_PATH)
# --- æœ¬åœ°çŠ¶æ€æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå¢é‡åŒæ­¥ï¼‰ ---
SYNC_STATE_FILE = resolve_repo_path(SYNC_STATE_PATH)
# --- æœ¬åœ°è¿è¡Œè®°å½•æ–‡ä»¶è·¯å¾„ ---
SYNC_RUN_LOG_FILE = resolve_repo_path(SYNC_RUN_LOG_PATH)

# --- å¢é‡åŒæ­¥ä¸ Git æŒä¹…åŒ–é…ç½® ---
INCREMENTAL_SYNC = os.getenv("INCREMENTAL_SYNC", "true").lower() in {"1", "true", "yes", "y"}
SYNC_STATE_GIT = os.getenv("SYNC_STATE_GIT", "true").lower() in {"1", "true", "yes", "y"}
SYNC_STATE_BRANCH = os.getenv("SYNC_STATE_BRANCH", "sync-state")
SYNC_STATE_REMOTE = os.getenv("SYNC_STATE_REMOTE", "origin")
SYNC_STATE_REMOTE_URL = os.getenv("SYNC_STATE_REMOTE_URL")

# --- éœ€è¦æ’é™¤çš„ç›®å½•ï¼ˆä¸æ‰«æè¿™äº›ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼‰ ---
EXCLUDE_DIRS = {'.git', '.github', 'node_modules', '__pycache__', '.vscode', '.idea', 'cnblogs_sync', '.cnblogs_sync'}

# --- å‡½æ•°å®šä¹‰ ---

def run_git(args, cwd=None, check=False):
    """è¿è¡Œ git å‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    cmd = ["git", "-c", "core.quotepath=false"] + args
    result = subprocess.run(
        cmd,
        cwd=cwd or REPO_ROOT,
        text=True,
        capture_output=True
    )
    if check and result.returncode != 0:
        raise RuntimeError(f"git {' '.join(args)} failed: {result.stderr.strip()}")
    return result

def is_git_repo():
    """æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦ä¸º Git ä»“åº“"""
    result = run_git(["rev-parse", "--is-inside-work-tree"])
    return result.returncode == 0 and result.stdout.strip() == "true"

def ensure_remote(remote, remote_url=None):
    """ç¡®ä¿ remote å­˜åœ¨å¹¶å¯ç”¨ï¼ˆå¯é€‰ï¼šè®¾ç½® PAT URLï¼‰"""
    if not remote_url:
        return
    result = run_git(["remote", "get-url", remote])
    if result.returncode != 0:
        run_git(["remote", "add", remote, remote_url], check=True)
        return
    current_url = result.stdout.strip()
    if current_url != remote_url:
        run_git(["remote", "set-url", remote, remote_url], check=True)

def has_remote(remote):
    """æ£€æŸ¥ remote æ˜¯å¦å­˜åœ¨"""
    result = run_git(["remote", "get-url", remote])
    return result.returncode == 0

def remote_branch_exists(remote, branch):
    """æ£€æŸ¥è¿œç«¯åˆ†æ”¯æ˜¯å¦å­˜åœ¨"""
    result = run_git(["ls-remote", "--heads", remote, branch])
    return result.returncode == 0 and bool(result.stdout.strip())

def ensure_git_identity(cwd):
    """ç¡®ä¿ git commit çš„ user.name/user.email å·²é…ç½®ï¼ˆCI/å®¹å™¨ç¯å¢ƒå¸¸ç¼ºçœï¼‰"""
    result_name = run_git(["config", "--get", "user.name"], cwd=cwd)
    result_email = run_git(["config", "--get", "user.email"], cwd=cwd)

    user_name = (result_name.stdout or "").strip() if result_name.returncode == 0 else ""
    user_email = (result_email.stdout or "").strip() if result_email.returncode == 0 else ""

    if not user_name:
        default_name = os.getenv("GIT_USER_NAME", "cnblogs-sync-bot")
        run_git(["config", "user.name", default_name], cwd=cwd, check=True)
    if not user_email:
        default_email = os.getenv("GIT_USER_EMAIL", "cnblogs-sync-bot@users.noreply.github.com")
        run_git(["config", "user.email", default_email], cwd=cwd, check=True)

def restore_state_from_git():
    """ä»ä¸“ç”¨åˆ†æ”¯æ¢å¤çŠ¶æ€æ–‡ä»¶ï¼ˆè®°å½• + å¢é‡çŠ¶æ€ï¼‰"""
    if not SYNC_STATE_GIT:
        return
    if not is_git_repo():
        print("âš ï¸ å½“å‰ç›®å½•ä¸æ˜¯ Git ä»“åº“ï¼Œæ— æ³•ä»åˆ†æ”¯æ¢å¤çŠ¶æ€")
        return

    try:
        ensure_remote(SYNC_STATE_REMOTE, SYNC_STATE_REMOTE_URL)
        if not has_remote(SYNC_STATE_REMOTE):
            print(f"âš ï¸ æœªæ‰¾åˆ° remote '{SYNC_STATE_REMOTE}'ï¼Œè¯·è®¾ç½® SYNC_STATE_REMOTE_URLï¼ˆå¸¦ PATï¼‰æˆ–ä»…æœ¬åœ°æµ‹è¯•æ—¶è®¾ç½® SYNC_STATE_GIT=false")
            return
        run_git(["fetch", SYNC_STATE_REMOTE, SYNC_STATE_BRANCH], check=True)
    except Exception as e:
        print(f"âš ï¸ æ‹‰å–åˆ†æ”¯å¤±è´¥ï¼Œè·³è¿‡çŠ¶æ€æ¢å¤ï¼š{e}")
        return

    for path in [SYNC_RECORD_FILE, SYNC_STATE_FILE, SYNC_RUN_LOG_FILE]:
        try:
            rel_path = path.relative_to(REPO_ROOT).as_posix()
        except ValueError:
            print(f"âš ï¸ çŠ¶æ€æ–‡ä»¶ä¸åœ¨ä»“åº“å†…ï¼Œè·³è¿‡æ¢å¤: {path}")
            continue
        result = run_git(["show", f"{SYNC_STATE_REMOTE}/{SYNC_STATE_BRANCH}:{rel_path}"])
        if result.returncode == 0:
            path.parent.mkdir(parents=True, exist_ok=True)
            path.write_text(result.stdout, encoding="utf-8")
            print(f"âœ… å·²ä»åˆ†æ”¯æ¢å¤çŠ¶æ€æ–‡ä»¶: {rel_path}")
        else:
            print(f"â„¹ï¸ åˆ†æ”¯æœªåŒ…å«çŠ¶æ€æ–‡ä»¶: {rel_path}")

def persist_state_to_git():
    """å°†çŠ¶æ€æ–‡ä»¶æäº¤åˆ°ä¸“ç”¨åˆ†æ”¯å¹¶æ¨é€"""
    if not SYNC_STATE_GIT:
        return True
    if not is_git_repo():
        print("âš ï¸ å½“å‰ç›®å½•ä¸æ˜¯ Git ä»“åº“ï¼Œæ— æ³•æŒä¹…åŒ–çŠ¶æ€")
        return False

    temp_dir = None
    try:
        ensure_remote(SYNC_STATE_REMOTE, SYNC_STATE_REMOTE_URL)
        if not has_remote(SYNC_STATE_REMOTE):
            print(f"âš ï¸ æœªæ‰¾åˆ° remote '{SYNC_STATE_REMOTE}'ï¼Œè¯·è®¾ç½® SYNC_STATE_REMOTE_URLï¼ˆå¸¦ PATï¼‰æˆ–ä»…æœ¬åœ°æµ‹è¯•æ—¶è®¾ç½® SYNC_STATE_GIT=false")
            return False
        branch_exists = remote_branch_exists(SYNC_STATE_REMOTE, SYNC_STATE_BRANCH)
        if branch_exists:
            run_git(["fetch", SYNC_STATE_REMOTE, SYNC_STATE_BRANCH], check=True)

        temp_dir = tempfile.mkdtemp(prefix="cnblogs-sync-state-")
        if branch_exists:
            run_git(
                ["worktree", "add", "-B", SYNC_STATE_BRANCH, temp_dir, f"{SYNC_STATE_REMOTE}/{SYNC_STATE_BRANCH}"],
                check=True
            )
        else:
            run_git(["worktree", "add", "-B", SYNC_STATE_BRANCH, temp_dir, "HEAD"], check=True)

        rel_paths = []
        for path in [SYNC_RECORD_FILE, SYNC_STATE_FILE, SYNC_RUN_LOG_FILE]:
            if not path.exists():
                continue
            try:
                rel_path = path.relative_to(REPO_ROOT)
            except ValueError:
                print(f"âš ï¸ çŠ¶æ€æ–‡ä»¶ä¸åœ¨ä»“åº“å†…ï¼Œæ— æ³•æŒä¹…åŒ–: {path}")
                continue
            dest_path = Path(temp_dir) / rel_path
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(path, dest_path)
            rel_paths.append(rel_path.as_posix())

        if not rel_paths:
            print("â„¹ï¸ æœªæ‰¾åˆ°å¯æŒä¹…åŒ–çš„çŠ¶æ€æ–‡ä»¶")
            return True

        status = run_git(["status", "--porcelain"], cwd=temp_dir)
        if not status.stdout.strip():
            print("â„¹ï¸ çŠ¶æ€æ–‡ä»¶æ— å˜åŒ–ï¼Œæ— éœ€æäº¤")
            return True

        run_git(["add"] + rel_paths, cwd=temp_dir, check=True)
        ensure_git_identity(temp_dir)
        commit_msg = f"chore: update cnblogs sync state ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})"
        run_git(["commit", "-m", commit_msg], cwd=temp_dir, check=True)
        run_git(["push", SYNC_STATE_REMOTE, SYNC_STATE_BRANCH], cwd=temp_dir, check=True)
        print(f"âœ… çŠ¶æ€å·²æ¨é€åˆ°åˆ†æ”¯: {SYNC_STATE_BRANCH}")
        return True
    except Exception as e:
        print(f"âŒ æŒä¹…åŒ–çŠ¶æ€å¤±è´¥: {e}")
        return False
    finally:
        if temp_dir:
            try:
                run_git(["worktree", "remove", temp_dir, "--force"])
            except Exception:
                pass
            try:
                if Path(temp_dir).exists():
                    shutil.rmtree(temp_dir, ignore_errors=True)
            except Exception:
                pass

def load_sync_state():
    """åŠ è½½å¢é‡åŒæ­¥çŠ¶æ€"""
    if SYNC_STATE_FILE.exists():
        try:
            with open(SYNC_STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½çŠ¶æ€æ–‡ä»¶æ—¶å‡ºé”™: {e}ï¼Œå°†ä½¿ç”¨ç©ºçŠ¶æ€")
            return {}
    return {}

def save_sync_state(state):
    """ä¿å­˜å¢é‡åŒæ­¥çŠ¶æ€"""
    try:
        with open(SYNC_STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜çŠ¶æ€æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def append_run_log(entry):
    """è¿½åŠ ä¸€è¡Œè¿è¡Œè®°å½•ï¼ˆJSONLï¼‰"""
    try:
        SYNC_RUN_LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(SYNC_RUN_LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"âš ï¸ å†™å…¥è¿è¡Œè®°å½•å¤±è´¥: {e}")

def get_head_commit():
    """è·å–å½“å‰ HEAD commit"""
    result = run_git(["rev-parse", "HEAD"])
    if result.returncode == 0:
        return result.stdout.strip()
    return None

def get_changed_markdown_files(last_commit, head_commit):
    """è·å–ä¸¤æ¬¡æäº¤ä¹‹é—´å˜æ›´çš„ Markdown æ–‡ä»¶"""
    if not last_commit or not head_commit:
        return None
    result = run_git(["diff", "--name-only", f"{last_commit}..{head_commit}", "--", "*.md"])
    if result.returncode != 0:
        print(f"âš ï¸ è·å–å¢é‡æ–‡ä»¶å¤±è´¥: {result.stderr.strip()}")
        return None

    changed_files = []
    for line in result.stdout.splitlines():
        rel = line.strip()
        if not rel:
            continue
        rel_path = Path(rel)
        if any(part in EXCLUDE_DIRS for part in rel_path.parts):
            continue
        abs_path = REPO_ROOT / rel_path
        if abs_path.exists():
            changed_files.append(str(abs_path))
    return changed_files

def find_all_markdown_files(root_dir=None):
    """é€’å½’æŸ¥æ‰¾ä»“åº“ä¸­æ‰€æœ‰çš„ Markdown æ–‡ä»¶"""
    if root_dir is None:
        # é»˜è®¤ä»è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰å¼€å§‹æ‰«æ
        root_dir = REPO_ROOT
    
    root_path = Path(root_dir).resolve()
    md_files = []
    
    print(f"ğŸ” å¼€å§‹æ‰«æ Markdown æ–‡ä»¶ï¼ˆä» {root_path} å¼€å§‹ï¼‰...")
    
    for file_path in root_path.rglob('*.md'):
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ä¸­æ˜¯å¦åŒ…å«éœ€è¦æ’é™¤çš„ç›®å½•
        relative_path = file_path.relative_to(root_path)
        path_parts = relative_path.parts
        
        # å¦‚æœè·¯å¾„çš„ä»»ä½•éƒ¨åˆ†åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼Œè·³è¿‡
        if any(part in EXCLUDE_DIRS for part in path_parts):
            continue
        
        md_files.append(str(file_path))
    
    md_files.sort()  # æŒ‰è·¯å¾„æ’åº
    print(f"âœ… æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶")
    return md_files

def get_file_content(filepath):
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

def replace_internal_md_links(content):
    """æŸ¥æ‰¾å†…å®¹ä¸­æ‰€æœ‰æŒ‡å‘æœ¬åœ° .md æ–‡ä»¶çš„é“¾æ¥ï¼Œå¹¶å°†å…¶æ›¿æ¢ä¸ºåšå®¢å›­ç«™å†…æœç´¢é“¾æ¥ã€‚"""
    md_link_pattern = re.compile(r'(\[.*?\])\((.*?\.md)\)')
    def replacer(match):
        link_text = match.group(1)
        md_path = match.group(2)
        keyword = os.path.basename(md_path).replace('.md', '')

        # æ ¸å¿ƒä¿®æ”¹ï¼šä¸å†å¯¹å…³é”®è¯è¿›è¡Œ URL ç¼–ç 
        # encoded_keyword = quote(keyword) # ç§»é™¤æ­¤è¡Œ

        # ç›´æ¥ä½¿ç”¨åŸå§‹å…³é”®è¯æ„å»º URL
        new_url = f"{CNBLOGS_SEARCH_URL}?Keywords={keyword}"
        return f"{link_text}({new_url} )"
    return md_link_pattern.sub(replacer, content)

def load_sync_record():
    """åŠ è½½æœ¬åœ°å‘å¸ƒè®°å½•"""
    if SYNC_RECORD_FILE.exists():
        try:
            with open(SYNC_RECORD_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å‘å¸ƒè®°å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}ï¼Œå°†ä½¿ç”¨ç©ºè®°å½•")
            return {}
    return {}

def save_sync_record(record):
    """ä¿å­˜æœ¬åœ°å‘å¸ƒè®°å½•"""
    try:
        with open(SYNC_RECORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(record, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å‘å¸ƒè®°å½•æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def get_blog_id(server):
    """è‡ªåŠ¨è·å– BLOG_IDï¼ˆCNBLOGS_BLOG_IDï¼‰"""
    try:
        blogs = server.blogger.getUsersBlogs('', USERNAME, PASSWORD)
        if blogs and len(blogs) > 0:
            blog = blogs[0] or {}
            blog_id = blog.get('blogid') or blog.get('blogId') or blog.get('id')
            return str(blog_id) if blog_id is not None else None
    except Exception as e:
        print(f"âš ï¸ è‡ªåŠ¨è·å– BLOG_ID å¤±è´¥: {e}")
    return None

def init_sync_record():
    """åˆå§‹åŒ–å‘å¸ƒè®°å½•ï¼šä» API è·å–æœ€è¿‘ 300 ç¯‡æ–‡ç« çš„æ ‡é¢˜å’Œ post_id"""
    global BLOG_ID
    if not all([RPC_URL, USERNAME, PASSWORD]):
        print("âŒ é”™è¯¯ï¼šä¸€ä¸ªæˆ–å¤šä¸ªç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæ— æ³•åˆå§‹åŒ–å‘å¸ƒè®°å½•")
        return False
    
    print("ğŸ”„ å¼€å§‹åˆå§‹åŒ–å‘å¸ƒè®°å½•ï¼ˆä» API è·å–æœ€è¿‘ 300 ç¯‡æ–‡ç« ï¼‰...")
    
    try:
        server = xmlrpc.client.ServerProxy(RPC_URL)
        if not BLOG_ID:
            BLOG_ID = get_blog_id(server)
            if not BLOG_ID:
                print("âŒ é”™è¯¯ï¼šCNBLOGS_BLOG_ID æœªè®¾ç½®ä¸”æ— æ³•è‡ªåŠ¨è·å–ï¼Œè¯·æ‰‹åŠ¨è®¾ç½® CNBLOGS_BLOG_ID")
                return False
            print(f"âœ… è‡ªåŠ¨è·å–åˆ° BLOG_ID: {BLOG_ID}")

        # API æé™æ˜¯ 300 ç¯‡
        recent_posts = server.metaWeblog.getRecentPosts(BLOG_ID, USERNAME, PASSWORD, 300)
        
        if not recent_posts:
            record = load_sync_record() or {}
            save_sync_record(record)
            print("â„¹ï¸ æœªè·å–åˆ°ä»»ä½•æ–‡ç« ï¼Œå·²åˆå§‹åŒ–ç©ºå‘å¸ƒè®°å½•")
            print(f"ğŸ“ è®°å½•æ–‡ä»¶ä¿å­˜åœ¨: {SYNC_RECORD_FILE}")
            return True
        
        # åˆå¹¶æ¨¡å¼ï¼šä¿ç•™æ—§è®°å½• + ç”¨æœ€è¿‘ 300 ç¯‡åˆ·æ–° post_idï¼ˆé¿å…å›  API é™åˆ¶ä¸¢å¤±æ—§æ˜ å°„ï¼‰
        record = load_sync_record() or {}
        for post in recent_posts:
            title = post.get('title', '').strip()
            post_id = post.get('postid')
            if title and post_id:
                record[title] = post_id
        
        # ä¿å­˜è®°å½•
        save_sync_record(record)
        print(f"âœ… æˆåŠŸåˆå§‹åŒ–å‘å¸ƒè®°å½•ï¼šå…± {len(record)} ç¯‡æ–‡ç« ")
        print(f"ğŸ“ è®°å½•æ–‡ä»¶ä¿å­˜åœ¨: {SYNC_RECORD_FILE}")
        return True
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å‘å¸ƒè®°å½•æ—¶å‡ºé”™: {e}")
        return False

def post_to_cnblogs(title, content, categories=None):
    """å‘å¸ƒæ–‡ç« åˆ°åšå®¢å›­ï¼ŒåŸºäºæœ¬åœ°è®°å½•åˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨
    è¿”å› True è¡¨ç¤ºæˆåŠŸå‘å¸ƒ/æ›´æ–°ï¼ŒFalse è¡¨ç¤ºè·³è¿‡æˆ–å¤±è´¥"""
    # --- æ­¥éª¤1: å‡†å¤‡æœ€ç»ˆå†…å®¹ ---

    # æ ¸å¿ƒä¿®æ”¹ï¼šä¸å†å¯¹æ ‡é¢˜è¿›è¡Œ URL ç¼–ç 
    # encoded_title = quote(title) # ç§»é™¤æ­¤è¡Œ

    # ç›´æ¥ä½¿ç”¨åŸå§‹æ ‡é¢˜æ„å»º URL
    knowledge_base_url = f"{KNOWLEDGE_BASE_URL}?q={title}"
    prepend_content = f"> å…³è”çŸ¥è¯†åº“ï¼š<a href=\"{knowledge_base_url}\">{title}</a>\r\n\r\n"

    processed_body = replace_internal_md_links(content)
    final_content = prepend_content + processed_body

    # --- æ­¥éª¤2: å‡†å¤‡ post æ•°æ®ç»“æ„ ---
    final_categories = ['[Markdown]']
    if categories and isinstance(categories, list):
        final_categories.extend(categories)
    else:
        final_categories.append('[éšç¬”åˆ†ç±»]')

    post_data = {
        'title': title,
        'description': final_content,
        'categories': final_categories,
        'publish': True
    }

    # --- æ­¥éª¤3: åŸºäºæœ¬åœ°è®°å½•çš„æ ¸å¿ƒå‘å¸ƒ/æ›´æ–°/è·³è¿‡é€»è¾‘ ---
    try:
        server = xmlrpc.client.ServerProxy(RPC_URL)
        
        # åŠ è½½æœ¬åœ°è®°å½•
        sync_record = load_sync_record()
        existing_post_id = sync_record.get(title)

        if existing_post_id:
            if FORCE_OVERWRITE_EXISTING:
                print(f"â„¹ï¸ æœ¬åœ°è®°å½•æ˜¾ç¤ºæ–‡ç«  '{title}' å·²å­˜åœ¨ï¼ˆPost ID: {existing_post_id}ï¼‰ï¼Œå¼ºåˆ¶è¦†ç›–æ¨¡å¼å·²å¼€å¯...")
                success = server.metaWeblog.editPost(existing_post_id, USERNAME, PASSWORD, post_data, post_data['publish'])
                if success:
                    print(f"âœ… æˆåŠŸæ›´æ–°æ–‡ç«  '{title}'ï¼ŒPost ID: {existing_post_id}")
                    # ç¡®ä¿è®°å½•ä¸­çš„ post_id æ˜¯æœ€æ–°çš„ï¼ˆè™½ç„¶é€šå¸¸ä¸ä¼šå˜ï¼‰
                    sync_record[title] = existing_post_id
                    save_sync_record(sync_record)
                    return True  # æˆåŠŸæ›´æ–°
                else:
                    print(f"âŒ æ›´æ–°æ–‡ç«  '{title}' å¤±è´¥")
                    return False  # æ›´æ–°å¤±è´¥
            else:
                print(f"â„¹ï¸ æœ¬åœ°è®°å½•æ˜¾ç¤ºæ–‡ç«  '{title}' å·²å­˜åœ¨ï¼ˆPost ID: {existing_post_id}ï¼‰ï¼Œè·³è¿‡å‘å¸ƒ")
                return False  # è·³è¿‡ï¼Œä¸ç®—æˆåŠŸå‘å¸ƒ
        else:
            print(f"ğŸ“„ æ–‡ç«  '{title}' ä¸åœ¨æœ¬åœ°è®°å½•ä¸­ï¼Œå°†åˆ›å»ºæ–°æ–‡ç« ")
            new_post_id = server.metaWeblog.newPost(BLOG_ID, USERNAME, PASSWORD, post_data, post_data['publish'])
            print(f"âœ… æˆåŠŸå‘å¸ƒæ–°æ–‡ç«  '{title}'ï¼Œæ–‡ç« ID: {new_post_id}")
            
            # æ›´æ–°æœ¬åœ°è®°å½•ï¼ˆå§‹ç»ˆæ›´æ–°ï¼‰
            sync_record[title] = new_post_id
            save_sync_record(sync_record)
            return True  # æˆåŠŸå‘å¸ƒ

    except Exception as e:
        print(f"âŒ å‘å¸ƒæˆ–æ›´æ–°æ–‡ç«  '{title}' æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return False  # å‘å¸ƒå¤±è´¥

# --- ä¸»é€»è¾‘ ---
if __name__ == "__main__":
    run_started_ts = time.time()
    missing_vars = []
    if not RPC_URL:
        missing_vars.append("CNBLOGS_RPC_URL")
    if not USERNAME:
        missing_vars.append("CNBLOGS_USERNAME")
    if not PASSWORD:
        missing_vars.append("CNBLOGS_TOKEN / CNBLOGS_PASSWORD")
    
    if missing_vars:
        print("âŒ é”™è¯¯ï¼šä»¥ä¸‹ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼š")
        for var in missing_vars:
            print(f"   - {var}")
        print("\nğŸ’¡ è¯·åˆ›å»º .env æ–‡ä»¶å¹¶è®¾ç½®è¿™äº›å˜é‡ï¼Œæˆ–é€šè¿‡ç¯å¢ƒå˜é‡ç›´æ¥è®¾ç½®ã€‚")
        sys.exit(1)

    # å¦‚æœå¼€å¯ Git çŠ¶æ€æŒä¹…åŒ–ï¼Œå…ˆå°è¯•æ¢å¤çŠ¶æ€æ–‡ä»¶
    restore_state_from_git()

    # BLOG_ID å¯é€‰ï¼šæœªè®¾ç½®åˆ™å°è¯•è‡ªåŠ¨è·å–
    if not BLOG_ID:
        try:
            server = xmlrpc.client.ServerProxy(RPC_URL)
            BLOG_ID = get_blog_id(server)
            if BLOG_ID:
                print(f"âœ… è‡ªåŠ¨è·å–åˆ° BLOG_ID: {BLOG_ID}")
            else:
                print("âŒ é”™è¯¯ï¼šCNBLOGS_BLOG_ID æœªè®¾ç½®ä¸”æ— æ³•è‡ªåŠ¨è·å–ï¼Œè¯·æ‰‹åŠ¨è®¾ç½® CNBLOGS_BLOG_ID")
                sys.exit(1)
        except Exception as e:
            print(f"âŒ è‡ªåŠ¨è·å– BLOG_ID å¤±è´¥: {e}")
            sys.exit(1)

    # è‡ªåŠ¨åˆå§‹åŒ–ï¼šæ²¡æœ‰å‘å¸ƒè®°å½•æ—¶å…ˆç”Ÿæˆï¼ˆé¿å…é‡å¤åˆ›å»ºæ–‡ç« ï¼‰
    if not SYNC_RECORD_FILE.exists():
        print("â„¹ï¸ æœªå‘ç°å‘å¸ƒè®°å½•ï¼Œå¼€å§‹è‡ªåŠ¨åˆå§‹åŒ–...")
        ok = init_sync_record()
        if not ok:
            sys.exit(1)
        if not persist_state_to_git():
            sys.exit(2)

    # è¯»å–å¢é‡åŒæ­¥çŠ¶æ€
    sync_state = load_sync_state()
    head_commit = get_head_commit()
    last_synced_commit = sync_state.get("last_synced_commit")

    # ç¡®å®šè¦å‘å¸ƒçš„æ–‡ä»¶åˆ—è¡¨
    run_mode = "full"
    manual_mode = len(sys.argv) > 1

    if len(sys.argv) > 1:
        # æ‰‹åŠ¨æ¨¡å¼ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šçš„æ–‡ä»¶
        files_to_publish = sys.argv[1:]
        print(f"ğŸ“ æ‰‹åŠ¨æ¨¡å¼ï¼šå‡†å¤‡å‘å¸ƒ {len(files_to_publish)} ä¸ªæŒ‡å®šæ–‡ä»¶")
        run_mode = "manual"
    else:
        files_to_publish = None
        if INCREMENTAL_SYNC:
            changed_files = get_changed_markdown_files(last_synced_commit, head_commit)
            if changed_files is not None:
                files_to_publish = changed_files
                run_mode = "incremental"
                print(f"ğŸ§© å¢é‡æ¨¡å¼ï¼šæ‰¾åˆ° {len(files_to_publish)} ä¸ªå˜æ›´ Markdown æ–‡ä»¶")

        if files_to_publish is None:
            # è‡ªåŠ¨æ¨¡å¼ï¼šæ‰«æä»“åº“ä¸­æ‰€æœ‰ Markdown æ–‡ä»¶
            files_to_publish = find_all_markdown_files()
            if not files_to_publish:
                print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• Markdown æ–‡ä»¶")
                sys.exit(0)
            print(f"ğŸ¤– å…¨é‡æ¨¡å¼ï¼šæ‰¾åˆ° {len(files_to_publish)} ä¸ª Markdown æ–‡ä»¶ï¼Œå‡†å¤‡å‘å¸ƒ")

    print()

    # å¢é‡æ¨¡å¼ä¸”æ²¡æœ‰å˜æ›´æ—¶ï¼Œç›´æ¥æ›´æ–°çŠ¶æ€å¹¶é€€å‡º
    if run_mode == "incremental" and not files_to_publish:
        print("â„¹ï¸ æœªæ£€æµ‹åˆ° Markdown å˜æ›´ï¼Œè·³è¿‡å‘å¸ƒ")
        if head_commit:
            sync_state["last_synced_commit"] = head_commit
        sync_state["last_run_at"] = datetime.now().isoformat(timespec="seconds")
        sync_state["last_run_mode"] = run_mode
        sync_state["last_total_candidates"] = 0
        sync_state["last_published_count"] = 0
        save_sync_state(sync_state)
        log_entry = {
            "ts": datetime.now().isoformat(timespec="seconds"),
            "mode": run_mode,
            "candidates": 0,
            "published": 0,
            "status": "no_change",
            "duration_s": int(time.time() - run_started_ts)
        }
        if head_commit:
            log_entry["head_commit"] = head_commit
        append_run_log(log_entry)
        if not persist_state_to_git():
            sys.exit(2)
        sys.exit(0)

    # é™æµé…ç½®ï¼šåŸºäºæˆåŠŸå‘å¸ƒçš„æ–‡ç« æ•°
    SUCCESS_BATCH_SIZE_SMALL = 5  # æ¯æˆåŠŸå‘å¸ƒ5ç¯‡ä¼‘æ¯
    SUCCESS_REST_SECONDS_SMALL = 3  # ä¼‘æ¯3ç§’
    
    SUCCESS_BATCH_SIZE_LARGE = 20  # æ¯æˆåŠŸå‘å¸ƒ20ç¯‡ä¼‘æ¯
    SUCCESS_REST_SECONDS_LARGE = 10  # ä¼‘æ¯10ç§’
    
    success_count = 0  # æˆåŠŸå‘å¸ƒçš„è®¡æ•°å™¨
    
    for idx, md_file in enumerate(files_to_publish, 1):
        if not os.path.exists(md_file):
            print(f"âš ï¸ æ–‡ä»¶ '{md_file}' ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
            continue

        print(f"\n[{idx}/{len(files_to_publish)}] å¤„ç†æ–‡ä»¶: {md_file}")
        post_title = os.path.basename(md_file).replace('.md', '')
        post_content = get_file_content(md_file)

        success = post_to_cnblogs(post_title, post_content)
        
        # å¦‚æœæˆåŠŸå‘å¸ƒï¼Œå¢åŠ æˆåŠŸè®¡æ•°å™¨
        if success:
            success_count += 1
            
            # æ¯æˆåŠŸå‘å¸ƒ 5 ç¯‡åä¼‘æ¯ 3 ç§’
            if success_count % SUCCESS_BATCH_SIZE_SMALL == 0:
                print(f"\nâ¸ï¸  å·²æˆåŠŸå‘å¸ƒ {success_count} ç¯‡æ–‡ç« ï¼Œä¼‘æ¯ {SUCCESS_REST_SECONDS_SMALL} ç§’...")
                time.sleep(SUCCESS_REST_SECONDS_SMALL)
                print("â–¶ï¸  ç»§ç»­å‘å¸ƒ...\n")
            
            # æ¯æˆåŠŸå‘å¸ƒ 20 ç¯‡åä¼‘æ¯ 10 ç§’
            if success_count % SUCCESS_BATCH_SIZE_LARGE == 0:
                print(f"\nâ¸ï¸  å·²æˆåŠŸå‘å¸ƒ {success_count} ç¯‡æ–‡ç« ï¼Œä¼‘æ¯ {SUCCESS_REST_SECONDS_LARGE} ç§’...")
                time.sleep(SUCCESS_REST_SECONDS_LARGE)
                print("â–¶ï¸  ç»§ç»­å‘å¸ƒ...\n")

    # è¿è¡Œç»“æŸåæ›´æ–°çŠ¶æ€ï¼ˆæ‰‹åŠ¨æ¨¡å¼ä¸æ›´æ–° last_synced_commitï¼‰
    if run_mode != "manual" and head_commit:
        sync_state["last_synced_commit"] = head_commit
    sync_state["last_run_at"] = datetime.now().isoformat(timespec="seconds")
    sync_state["last_run_mode"] = run_mode
    sync_state["last_total_candidates"] = len(files_to_publish)
    sync_state["last_published_count"] = success_count
    save_sync_state(sync_state)
    log_entry = {
        "ts": datetime.now().isoformat(timespec="seconds"),
        "mode": run_mode,
        "candidates": len(files_to_publish),
        "published": success_count,
        "status": "completed",
        "duration_s": int(time.time() - run_started_ts)
    }
    if head_commit:
        log_entry["head_commit"] = head_commit
    append_run_log(log_entry)

    if not persist_state_to_git():
        sys.exit(2)
