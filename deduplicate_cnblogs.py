# deduplicate_cnblogs.py
# -*- coding: utf-8 -*-
# ä¿®å¤æ€§è„šæœ¬ï¼Œä¸åœ¨ä¸»æµç¨‹ä¸­è°ƒç”¨

import os
import sys
import time
import json
import xmlrpc.client
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

# --- é…ç½®ä¿¡æ¯ ---
RPC_URL = os.getenv("CNBLOGS_RPC_URL")
USERNAME = os.getenv("CNBLOGS_USERNAME")
TOKEN = os.getenv("CNBLOGS_TOKEN")
# BLOG_ID å¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™é€šè¿‡ API è‡ªåŠ¨è·å–
BLOG_ID = None  # è‡ªåŠ¨è·å–

# å¯é€‰ï¼šåŒæ­¥è„šæœ¬çš„å‘å¸ƒè®°å½•æ–‡ä»¶ï¼ˆç”¨äºå»é‡åä¿®æ­£æœ¬åœ°è®°å½•ï¼Œé¿å… record æŒ‡å‘è¢«åˆ çš„ post_idï¼‰
REPO_ROOT = Path.cwd().resolve()
SYNC_RECORD_PATH = ".cnblogs_sync/.cnblogs_sync_record.json"
SYNC_RECORD_FILE = Path(SYNC_RECORD_PATH)
if not SYNC_RECORD_FILE.is_absolute():
    SYNC_RECORD_FILE = (REPO_ROOT / SYNC_RECORD_FILE).resolve()

# è¯´æ˜ï¼šæœ¬è„šæœ¬ä¼šâ€œåˆ é™¤â€åšå®¢å›­ä¸Šçš„é‡å¤æ–‡ç« ï¼›åŒæ—¶ä¼šå°è¯•æŠŠæœ¬åœ°å‘å¸ƒè®°å½•ï¼ˆSYNC_RECORD_PATHï¼‰ä¿®æ­£ä¸ºä¿ç•™çš„ post_idã€‚

def load_sync_record():
    """åŠ è½½åŒæ­¥è„šæœ¬çš„å‘å¸ƒè®°å½•ï¼ˆä¸å­˜åœ¨åˆ™è¿”å› Noneï¼‰"""
    if not SYNC_RECORD_FILE.exists():
        return None
    try:
        return json.loads(SYNC_RECORD_FILE.read_text(encoding="utf-8"))
    except Exception as e:
        print(f"âš ï¸ åŠ è½½å‘å¸ƒè®°å½•æ–‡ä»¶å¤±è´¥ï¼Œå°†è·³è¿‡æ›´æ–°: {SYNC_RECORD_FILE} ({e})")
        return None

def save_sync_record(record):
    """ä¿å­˜åŒæ­¥è„šæœ¬çš„å‘å¸ƒè®°å½•"""
    try:
        SYNC_RECORD_FILE.parent.mkdir(parents=True, exist_ok=True)
        SYNC_RECORD_FILE.write_text(
            json.dumps(record, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        print(f"âœ… å·²æ›´æ–°å‘å¸ƒè®°å½•æ–‡ä»¶: {SYNC_RECORD_FILE}")
        return True
    except Exception as e:
        print(f"âš ï¸ å†™å…¥å‘å¸ƒè®°å½•æ–‡ä»¶å¤±è´¥: {SYNC_RECORD_FILE} ({e})")
        return False

# --- é…ç½®é€‰é¡¹ ---
KEEP_LATEST = True  # True: ä¿ç•™æœ€æ–°çš„ï¼Œåˆ é™¤æ—§çš„ï¼›False: ä¿ç•™æœ€æ—©çš„ï¼Œåˆ é™¤æ–°çš„
DRY_RUN = False  # True: åªæ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ–‡ç« ï¼Œä¸å®é™…åˆ é™¤ï¼›False: å®é™…æ‰§è¡Œåˆ é™¤
SHOW_DETAILS = False  # True: æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†è¿‡ç¨‹ï¼›False: åªæ˜¾ç¤ºç»Ÿè®¡å’Œåˆ—è¡¨
DELETE_DELAY = 0  # åˆ é™¤æ“ä½œä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œ0 è¡¨ç¤ºæ— å»¶è¿Ÿ

def get_blog_id(server):
    """é€šè¿‡ API è·å–åšå®¢ID"""
    try:
        blogs = server.blogger.getUsersBlogs('', USERNAME, TOKEN)
        if blogs and len(blogs) > 0:
            blog_id = blogs[0].get('blogid')
            print(f"âœ… è·å–åˆ°åšå®¢ID: {blog_id}")
            return blog_id
        else:
            print("âš ï¸ æœªæ‰¾åˆ°åšå®¢ä¿¡æ¯")
            return None
    except Exception as e:
        print(f"âš ï¸ è·å–åšå®¢IDæ—¶å‡ºé”™: {e}")
        return None

def normalize_title(title):
    """æ ‡å‡†åŒ–æ ‡é¢˜ï¼Œç”¨äºåŒ¹é…ï¼ˆå»é™¤é¦–å°¾ç©ºæ ¼ï¼‰"""
    return title.strip() if title else ""

def get_all_posts(server, max_posts=300):
    """è·å–æ‰€æœ‰æ–‡ç« ï¼ˆgetRecentPosts API æé™æ˜¯ 300 ç¯‡ï¼Œä¸æ”¯æŒåˆ†é¡µï¼‰"""
    all_posts = []
    all_post_ids = set()  # ç”¨äºå»é‡
    
    # API æé™æ˜¯ 300ï¼Œè¶…è¿‡ 300 ä¹Ÿæ²¡ç”¨
    request_count = min(max_posts, 300)
    
    print(f"ğŸ“¥ å¼€å§‹è·å–æ–‡ç« åˆ—è¡¨ï¼ˆè¯·æ±‚ {request_count} ç¯‡ï¼ŒAPI æé™æ˜¯ 300 ç¯‡ï¼‰...")
    
    try:
        posts = server.metaWeblog.getRecentPosts(BLOG_ID, USERNAME, TOKEN, request_count)
        
        if posts:
            # ä½¿ç”¨ postid å»é‡ï¼Œé¿å…é‡å¤æ·»åŠ 
            for post in posts:
                post_id = post.get('postid')
                if post_id and post_id not in all_post_ids:
                    all_posts.append(post)
                    all_post_ids.add(post_id)
            
            print(f"  âœ“ API è¿”å› {len(posts)} ç¯‡æ–‡ç« ")
            print(f"  âœ“ å»é‡åå¾—åˆ° {len(all_posts)} ç¯‡ä¸é‡å¤æ–‡ç« ")
            
            # å¦‚æœè¿”å›çš„æ–‡ç« æ•°æ­£å¥½æ˜¯ 300ï¼Œæç¤ºå¯èƒ½è¿˜æœ‰æ›´å¤šæ–‡ç« 
            if len(posts) == 300:
                print(f"  âš ï¸ æ³¨æ„ï¼šè¿”å›äº† 300 ç¯‡æ–‡ç« ï¼ˆAPI æé™ï¼‰ï¼Œå¯èƒ½è¿˜æœ‰æ›´æ—©çš„æ–‡ç« æœªè·å–")
                print(f"  ğŸ’¡ æç¤ºï¼šå¦‚æœæ–‡ç« æ€»æ•°è¶…è¿‡ 300ï¼Œéœ€è¦åˆ é™¤éƒ¨åˆ†æ–‡ç« åæ‰èƒ½è·å–åˆ°æ›´æ—©çš„æ–‡ç« ")
        else:
            print("  â„¹ï¸ æœªè·å–åˆ°ä»»ä½•æ–‡ç« ")
            
    except Exception as e:
        print(f"âš ï¸ è·å–æ–‡ç« æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"âœ… å…±è·å– {len(all_posts)} ç¯‡ä¸é‡å¤æ–‡ç« \n")
    return all_posts

def find_duplicates(posts):
    """æ‰¾å‡ºé‡å¤çš„æ–‡ç« ï¼ŒæŒ‰æ ‡é¢˜åˆ†ç»„"""
    title_groups = defaultdict(list)
    
    for post in posts:
        title = normalize_title(post.get('title', ''))
        if title:
            title_groups[title].append(post)
    
    # æ‰¾å‡ºæœ‰é‡å¤çš„æ ‡é¢˜
    duplicates = {title: posts_list for title, posts_list in title_groups.items() if len(posts_list) > 1}
    
    return duplicates

def parse_date(date_value):
    """è§£ææ—¥æœŸå€¼ï¼Œè¿”å› datetime å¯¹è±¡ç”¨äºæ¯”è¾ƒ"""
    try:
        if isinstance(date_value, datetime):
            return date_value
        if isinstance(date_value, str):
            # å°è¯•è§£æå¸¸è§æ ¼å¼
            for fmt in ['%Y%m%dT%H:%M:%S', '%Y-%m-%d %H:%M:%S', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%S%z']:
                try:
                    return datetime.strptime(date_value, fmt)
                except:
                    continue
        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢
        return datetime.fromisoformat(str(date_value)) if hasattr(datetime, 'fromisoformat') else datetime.now()
    except:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå¾ˆæ—©çš„æ—¥æœŸï¼Œè¿™æ ·ä¼šè¢«æ’åˆ°æœ€å
        return datetime(1970, 1, 1)

def format_date(date_value):
    """æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º"""
    try:
        dt = parse_date(date_value)
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    except:
        return str(date_value)

def delete_post(server, post_id, title):
    """åˆ é™¤æŒ‡å®šæ–‡ç« ï¼ˆä½¿ç”¨ blogger.deletePostï¼‰"""
    try:
        # æ ¹æ® API æ–‡æ¡£ï¼šblogger.deletePost(appKey, postid, username, password, publish)
        # appKey å¯ä»¥ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œpublish è®¾ä¸º True
        print(f"      ğŸ“ è°ƒç”¨åˆ é™¤æ¥å£:")
        print(f"         æ–¹æ³•: blogger.deletePost")
        print(f"         å‚æ•°: appKey='', postid='{post_id}', username='{USERNAME}', password='***', publish=True")
        print(f"         RPC URL: {RPC_URL}")
        
        result = server.blogger.deletePost('', post_id, USERNAME, TOKEN, True)
        
        print(f"      ğŸ“¥ æ¥å£è¿”å›: {result}")
        print(f"         è¿”å›å€¼ç±»å‹: {type(result).__name__}")
        print(f"         è¿”å›å€¼å†…å®¹: {repr(result)}")
        
        # æ£€æŸ¥è¿”å›å€¼
        if result is True or result == True:
            print(f"      âœ… æ¥å£è¿”å› Trueï¼Œè¡¨ç¤ºåˆ é™¤æˆåŠŸ")
            return True
        elif result is False or result == False:
            print(f"      âŒ æ¥å£è¿”å› Falseï¼Œè¡¨ç¤ºåˆ é™¤å¤±è´¥")
            return False
        else:
            print(f"      âš ï¸ æ¥å£è¿”å›äº†æ„å¤–çš„å€¼: {result}")
            return False
            
    except Exception as e:
        print(f"      âŒ æ¥å£è°ƒç”¨å¤±è´¥:")
        print(f"         é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"         é”™è¯¯ä¿¡æ¯: {e}")
        import traceback
        print(f"      ğŸ“‹ é”™è¯¯å †æ ˆ:")
        for line in traceback.format_exc().split('\n')[:5]:
            if line.strip():
                print(f"         {line}")
        return False

def deduplicate_one_round(server):
    """æ‰§è¡Œä¸€è½®å»é‡ï¼Œè¿”å›æ˜¯å¦è¿˜æœ‰é‡å¤æ–‡ç« """
    global BLOG_ID

    sync_record = load_sync_record()
    updated_record = False
    
    # 1. è·å–æ‰€æœ‰æ–‡ç« ï¼ˆAPI æé™æ˜¯ 300 ç¯‡ï¼‰
    all_posts = get_all_posts(server, max_posts=300)
    
    if not all_posts:
        print("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ç« ã€‚")
        return False  # æ²¡æœ‰æ–‡ç« ï¼Œä¸éœ€è¦ç»§ç»­
    
    # 2. æ‰¾å‡ºé‡å¤çš„æ–‡ç« 
    duplicates = find_duplicates(all_posts)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_posts = len(all_posts)
    duplicate_titles_count = len(duplicates)
    duplicate_posts_count = sum(len(posts) for posts in duplicates.values())
    unique_posts_count = total_posts - duplicate_posts_count + duplicate_titles_count  # ä¸é‡å¤çš„æ–‡ç« æ•°ï¼ˆæ¯ç»„ç®—1ç¯‡ï¼‰
    
    print("=" * 80)
    print("ğŸ“Š æ–‡ç« ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 80)
    print(f"æ€»æ–‡ç« æ•°: {total_posts} ç¯‡")
    print(f"ä¸é‡å¤æ–‡ç« : {unique_posts_count} ç¯‡")
    print(f"é‡å¤æ ‡é¢˜æ•°: {duplicate_titles_count} ä¸ª")
    print(f"é‡å¤æ–‡ç« æ€»æ•°: {duplicate_posts_count} ç¯‡")
    print(f"å°†åˆ é™¤æ–‡ç« æ•°: {duplicate_posts_count - duplicate_titles_count} ç¯‡")
    print()
    
    if not duplicates:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤æ–‡ç« ï¼")
        return False  # æ²¡æœ‰é‡å¤ï¼Œä¸éœ€è¦ç»§ç»­
    
    # 3. åˆ—å‡ºæ‰€æœ‰é‡å¤æ ‡é¢˜
    print("=" * 80)
    print("ğŸ“‹ é‡å¤æ ‡é¢˜è¯¦ç»†åˆ—è¡¨ï¼ˆæŒ‰é‡å¤æ•°é‡æ’åºï¼‰")
    print("=" * 80)
    
    # æŒ‰é‡å¤æ•°é‡æ’åº
    sorted_duplicates = sorted(duplicates.items(), key=lambda x: len(x[1]), reverse=True)
    
    for idx, (title, posts_list) in enumerate(sorted_duplicates, 1):
        print(f"{idx:3d}. [{len(posts_list)} ç¯‡é‡å¤] {title}")
        # æ˜¾ç¤ºå‰5ç¯‡æ–‡ç« çš„ID
        show_count = min(5, len(posts_list))
        post_ids = [str(post.get('postid', 'N/A')) for post in posts_list[:show_count]]
        print(f"     æ–‡ç« IDç¤ºä¾‹: {', '.join(post_ids)}")
        if len(posts_list) > 5:
            print(f"     ... è¿˜æœ‰ {len(posts_list) - 5} ç¯‡")
    
    print()
    
    print("=" * 80)
    print("ğŸ” å¼€å§‹å¤„ç†é‡å¤æ–‡ç« ...")
    print("=" * 80)
    print()
    
    # 4. å¤„ç†æ¯ä¸ªé‡å¤ç»„ï¼ˆä¼˜å…ˆä¿ç•™æœ€æ–°çš„ï¼‰
    total_to_delete = 0
    total_kept = 0
    total_deleted = 0
    total_failed = 0
    
    for title, posts_list in duplicates.items():
        print(f"ğŸ“„ æ ‡é¢˜: {title}")
        print(f"   é‡å¤æ•°é‡: {len(posts_list)} ç¯‡")
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆä¼˜å…ˆä¿ç•™æœ€æ–°çš„ï¼‰
        try:
            # ä½¿ç”¨ parse_date å‡½æ•°æ­£ç¡®è§£æå’Œæ¯”è¾ƒæ—¶é—´
            posts_list.sort(key=lambda p: parse_date(p.get('dateCreated', p.get('pubDate', ''))), reverse=KEEP_LATEST)
        except:
            # å¦‚æœæ’åºå¤±è´¥ï¼ŒæŒ‰ postid æ’åºï¼ˆé€šå¸¸ postid è¶Šå¤§è¶Šæ–°ï¼‰
            try:
                posts_list.sort(key=lambda p: int(p.get('postid', 0)), reverse=KEEP_LATEST)
            except:
                pass
        
        # ä¿ç•™ç¬¬ä¸€ç¯‡ï¼ˆæœ€æ–°çš„ï¼‰ï¼Œåˆ é™¤å…¶ä½™çš„ï¼ˆæ—§çš„ï¼‰
        keep_post = posts_list[0]
        delete_posts = posts_list[1:]
        
        print(f"   âœ“ ä¿ç•™: Post ID {keep_post.get('postid')} (åˆ›å»ºæ—¶é—´: {format_date(keep_post.get('dateCreated', keep_post.get('pubDate', 'N/A')))})")

        # å¦‚æœå­˜åœ¨æœ¬åœ°å‘å¸ƒè®°å½•æ–‡ä»¶ï¼Œé¡ºæ‰‹æŠŠè¯¥æ ‡é¢˜çš„ post_id ä¿®æ­£ä¸ºâ€œä¿ç•™çš„é‚£ç¯‡â€
        if sync_record is not None and not DRY_RUN:
            keep_id = keep_post.get('postid')
            if keep_id is not None:
                sync_record[title] = keep_id
                updated_record = True
        
        for post in delete_posts:
            post_id = post.get('postid')
            post_date = format_date(post.get('dateCreated', post.get('pubDate', 'N/A')))
            
            if DRY_RUN:
                print(f"   ğŸ—‘ï¸  [æ¨¡æ‹Ÿ] å°†åˆ é™¤: Post ID {post_id} (åˆ›å»ºæ—¶é—´: {post_date})")
                total_to_delete += 1
            else:
                print(f"   ğŸ—‘ï¸  æ­£åœ¨åˆ é™¤: Post ID {post_id} (åˆ›å»ºæ—¶é—´: {post_date})")
                print(f"      æ ‡é¢˜: {title[:60]}{'...' if len(title) > 60 else ''}")
                success = delete_post(server, post_id, title)
                if success:
                    print(f"      âœ… åˆ é™¤æˆåŠŸ")
                    total_deleted += 1
                else:
                    print(f"      âŒ åˆ é™¤å¤±è´¥")
                    total_failed += 1
                total_to_delete += 1
                if DELETE_DELAY > 0:
                    time.sleep(DELETE_DELAY)
                print()  # ç©ºè¡Œåˆ†éš”
        
        total_kept += 1
        print()  # ç©ºè¡Œåˆ†éš”æ¯ä¸ªæ ‡é¢˜ç»„
    
    # 5. æ€»ç»“
    print("=" * 60)
    if DRY_RUN:
        print(f"ğŸ“Š [æ¨¡æ‹Ÿæ¨¡å¼] ç»Ÿè®¡:")
        print(f"   - å°†ä¿ç•™: {total_kept} ç¯‡æ–‡ç« ï¼ˆæ¯ç»„ä¿ç•™1ç¯‡æœ€æ–°çš„ï¼‰")
        print(f"   - å°†åˆ é™¤: {total_to_delete} ç¯‡é‡å¤æ–‡ç« ï¼ˆæ—§çš„ï¼‰")
        print(f"\nğŸ’¡ æç¤º: å°† DRY_RUN è®¾ç½®ä¸º False åé‡æ–°è¿è¡Œä»¥å®é™…æ‰§è¡Œåˆ é™¤")
    else:
        print(f"ğŸ“Š ç»Ÿè®¡:")
        print(f"   - å·²ä¿ç•™: {total_kept} ç¯‡æ–‡ç« ï¼ˆæ¯ç»„ä¿ç•™1ç¯‡æœ€æ–°çš„ï¼‰")
        print(f"   - å·²åˆ é™¤: {total_deleted} ç¯‡é‡å¤æ–‡ç« ï¼ˆæ—§çš„ï¼‰")
        if total_failed > 0:
            print(f"   - åˆ é™¤å¤±è´¥: {total_failed} ç¯‡")
    print("=" * 60)
    print()

    # å»é‡å®Œæˆåï¼Œè‹¥æœ‰æœ¬åœ°å‘å¸ƒè®°å½•æ–‡ä»¶ï¼Œåˆ™è½ç›˜ä¸€æ¬¡ï¼ˆé¿å… record æŒ‡å‘è¢«åˆ çš„ post_idï¼‰
    if sync_record is not None:
        if DRY_RUN:
            print(f"â„¹ï¸ DRY_RUN=trueï¼šæœªæ›´æ–°å‘å¸ƒè®°å½•æ–‡ä»¶: {SYNC_RECORD_FILE}")
        elif updated_record:
            save_sync_record(sync_record)
    
    return True  # æœ‰é‡å¤ï¼Œå·²å¤„ç†

def deduplicate_posts():
    """ä¸»å»é‡é€»è¾‘ï¼ˆè¿­ä»£æ¨¡å¼ï¼šç›´åˆ°æ²¡æœ‰é‡å¤æ–‡ç« ï¼‰"""
    global BLOG_ID
    
    missing_vars = []
    if not RPC_URL:
        missing_vars.append("CNBLOGS_RPC_URL")
    if not USERNAME:
        missing_vars.append("CNBLOGS_USERNAME")
    if not TOKEN:
        missing_vars.append("CNBLOGS_TOKEN")
    
    if missing_vars:
        print("âŒ é”™è¯¯ï¼šä»¥ä¸‹ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼š")
        for var in missing_vars:
            print(f"   - {var}")
        print("\nğŸ’¡ è¯·åˆ›å»º .env æ–‡ä»¶å¹¶è®¾ç½®è¿™äº›å˜é‡ï¼Œæˆ–é€šè¿‡ç¯å¢ƒå˜é‡ç›´æ¥è®¾ç½®ã€‚")
        print("   BLOG_ID å¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™é€šè¿‡ API è‡ªåŠ¨è·å–ã€‚")
        sys.exit(1)
    
    try:
        server = xmlrpc.client.ServerProxy(RPC_URL)
        
        # å¦‚æœ BLOG_ID æœªè®¾ç½®ï¼Œè‡ªåŠ¨è·å–
        if not BLOG_ID:
            BLOG_ID = get_blog_id(server)
            if not BLOG_ID:
                print("âŒ æ— æ³•è·å–åšå®¢IDï¼Œé€€å‡ºã€‚")
                sys.exit(1)
            print()
        
        # è¿­ä»£æ¨¡å¼ï¼šå¾ªç¯æ‰§è¡Œç›´åˆ°æ²¡æœ‰é‡å¤æ–‡ç« 
        round_num = 1
        max_rounds = 50  # é˜²æ­¢æ— é™å¾ªç¯
        
        while round_num <= max_rounds:
            print("=" * 80)
            print(f"ğŸ”„ ç¬¬ {round_num} è½®å»é‡")
            print("=" * 80)
            print()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤
            has_duplicates = deduplicate_one_round(server)
            
            if not has_duplicates:
                print("=" * 80)
                print(f"âœ… å®Œæˆï¼ç»è¿‡ {round_num} è½®å»é‡ï¼Œå·²æ— é‡å¤æ–‡ç« ")
                print("=" * 80)
                break
            
            # å¦‚æœæœ‰é‡å¤ï¼Œç»§ç»­ä¸‹ä¸€è½®
            round_num += 1
            if round_num <= max_rounds:
                print(f"â³ ç­‰å¾… 2 ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                time.sleep(2)
                print()
        
        if round_num > max_rounds:
            print("=" * 80)
            print(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§è½®æ•°é™åˆ¶ ({max_rounds} è½®ï¼‰ï¼Œåœæ­¢è¿­ä»£")
            print("=" * 80)
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    print("ğŸš€ åšå®¢å›­æ–‡ç« å»é‡å·¥å…·")
    print(f"   æ¨¡å¼: {'æ¨¡æ‹Ÿè¿è¡Œ' if DRY_RUN else 'å®é™…åˆ é™¤'}")
    print(f"   ç­–ç•¥: {'ä¿ç•™æœ€æ–°' if KEEP_LATEST else 'ä¿ç•™æœ€æ—©'}")
    print()
    
    deduplicate_posts()
